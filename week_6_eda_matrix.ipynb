{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "This week will work through the following:\n",
    "\n",
    "* Data Loading - There will be no problems on this just read the cells to see how to load data from sources.\n",
    "* EDA (Exploritory Data Analysis) - There are five problems in this section to complete and share in class.\n",
    "* Matrix Operations - There are four problems in this section to complete and share in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading & Saving Data\n",
    "\n",
    "### Reading\n",
    "- https://wesmckinney.com/book/accessing-data.html\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "- Loading data from files\n",
    "- Loading data from a database\n",
    "- loading data from the internet\n",
    "- Saving data to files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data into Pandas\n",
    "\n",
    "Pandas can import structured data from a variety of file formats and data sources.\n",
    "\n",
    "File can be in plain-text or in certain binary formats Pandas recognizes.\n",
    "\n",
    "Files can be on the same computer as your program or on a remote system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data-loading Methods\n",
    "\n",
    "Some common methods and file formats are:\n",
    "\n",
    "- **read_csv** - read delimited values from .csv or .tsv files\n",
    "- **read_html** - read tables from a .html file\n",
    "- **read_excel** - read .xls, .xlsx Excel spreadsheets\n",
    "- **read_json** - read JavaScript Object Notation (JSON) from .json files\n",
    "- **read_sas** - read a dataset created by SAS\n",
    "- **read_spss** - read a data file created by SPSS\n",
    "- **read_xml** - .xml - Extensible Markup Language\n",
    "- **read_sql** - read results of an SQL query\n",
    "- **read_sql_table** - read a whole SQL table (similar to everything in a table using `read_sql`)\n",
    "\n",
    "These methods only work when the data is in a tabular form. If the data isn’t tabular (e.g. with complex or nested data), the read method will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Options\n",
    "\n",
    "All the above methods convert input data into a DataFrame. But they vary according to optional arguments for how to interpret the data.\n",
    "\n",
    "Some coomon considerations are:\n",
    "\n",
    "- **Indexing** - which columns to read and whether to get colkumn names from the file\n",
    "- **Type inference** - converting data to optimal types\n",
    "- **Date & time parsing** - identifying date/time values and combining multiple columns into one\n",
    "- **Chunked iteration** - reading large files in chunks\n",
    "- **Handling dirty data** - Includes skipping rows or comments, formatting numeric data, etc.\n",
    "\n",
    "See a full list of [options for reading CSV files](https://wesmckinney.com/book/accessing-data#tbl-table_read_csv_function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data From Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Files\n",
    "\n",
    "Pandas can read files located on the same computer using relative or absolute file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file in same directory\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# file path relative to current directory. \n",
    "# Meaning if you had a folder called `examples` in this repo you could access it with the command below. \n",
    "#df = pd.read_csv(\"examples/data.csv\")\n",
    "\n",
    "# absolute file path\n",
    "#df = pd.read_csv(\"/usr/johndoe/examples/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example data from pulic internet location\n",
    "url = \"https://data.cdc.gov/api/views/v6ab-adf5/rows.csv?accessType=DOWNLOAD\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's helpful to retrieve a file from the internet and save to disk before reading into a DataFrame.\n",
    "\n",
    "Python's `urllib.request` module is helpful for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "data_url = \"https://data.cdc.gov/api/views/v6ab-adf5/rows.csv?accessType=DOWNLOAD\"\n",
    "request.urlretrieve(data_url, filename='mortality_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SQL\n",
    "\n",
    "Python has libraries for interacting with common relational database platforms:\n",
    "\n",
    "- sqlite3 - SQLite\n",
    "- pymysql - MySQL\n",
    "- psycopg2 - PostgreSQL\n",
    "- cx_oracle - Oracle\n",
    "- pymssql - MS SQL Server\n",
    "\n",
    "You can `query` a database from Python by:\n",
    "\n",
    "- creating a connection object with the `connect()` method\n",
    "- getting a cursor object with the `cursor()` method\n",
    "- executing an SQL query to fetch desired rows with `execute()` and `fetchall()`\n",
    "\n",
    "For example, to list the tables in a database:\n",
    "```\n",
    "import sqlite3\n",
    "fires_con = sqlite3.connect('Data/FPA_FOD_20170508.sqlite')\n",
    "fires_cur = fires_con.cursor()\n",
    "'SELECT name FROM sqlite_master WHERE type=\"table\"').fetchall()\n",
    "```\n",
    "\n",
    "SQL query results can be read directly into a DataFrame using the `read_sql_query` method:\n",
    "\n",
    "```\n",
    "fires = pd.read_sql_query(\n",
    "'''SELECT STATE, FIRE_YEAR, DATETIME(DISCOVERY_DATE) AS DISCOVERY_DATE, FIRE_NAME, FIRE_SIZE, LATITUDE, LONGITUDE FROM Fires''', fires_con)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with JSON Data\n",
    "\n",
    "The JSON format is popular for transmitting data between applications and closely matches the structure of a Python `dict`, with the exception of its `null` value and some other minor syntax differences.\n",
    "\n",
    "There are several Python libraries for handling JSON, including `json` which is built into Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "json_string = \"\"\"\n",
    "{\n",
    "  \"state\": \"AK\",\n",
    "  \"cities\": [\n",
    "  {\"name\": \"Anchorage\", \"pop\": 250000, \"region\": \"south-central\"},\n",
    "  {\"name\": \"Fairbanks\", \"pop\": 75000, \"region\": \"interior\"},\n",
    "  {\"name\": \"Juneau\", \"pop\": 25000, \"region\": \"south-east\"}\n",
    "  ],\n",
    "  \"industries\": [\"fishing\",\"mining\",\"tourism\"]\n",
    "}\n",
    "\"\"\"\n",
    "from pprint import pprint as pp\n",
    "import json\n",
    "data = json.loads(json_string)\n",
    "\n",
    "# use pretty-print to print formatted json data\n",
    "pp(data)\n",
    "\n",
    "cities = pd.DataFrame(data[\"cities\"], columns=[\"name\", \"pop\"])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Reading\n",
    "\n",
    "- https://www.geeksforgeeks.org/what-is-exploratory-data-analysis/\n",
    "- https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15\n",
    "- https://greenteapress.com/thinkstats2/html/thinkstats2002.html\n",
    "\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "- exploratory data analysis\n",
    "- common data plots - line, bar, scatter, histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory data analysis (EDA), is a crucial initial step for understanding a dataset and preparing for statistical analysis.\n",
    "\n",
    "EDA answers questions such as:\n",
    "- what is the data quality?\n",
    "- what patterns are evident in the data?\n",
    "- is the data ready to support analysis & conclusions?\n",
    "\n",
    "EDA is the process of performing initial investigations to:\n",
    "- Uncover underlying structure & patterns in the data\n",
    "- Identify important variables\n",
    "- Identify anomalies\n",
    "- Set the stage for statisical analysis & visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the data\n",
    "This problem will be a collection of easier tasks. Fill in the 5 empty cells below to complete this problem. \n",
    "\n",
    "As a first step, it's important to know your data's composition:\n",
    "\n",
    "- how many observations?\n",
    "- how many features (variables)?\n",
    "- what does your data look like?\n",
    "- which are the dependent variables?\n",
    "- are any data missing or incorrect?\n",
    "- what are the primary statistics for each feature?\n",
    "- what are the data types?\n",
    "- are variables numeric or categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sample data\n",
    "download_url = (\"https://raw.githubusercontent.com/fivethirtyeight/data/master/bechdel/movies.csv\")\n",
    "movie_df = pd.read_csv(download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1a**\n",
    "\n",
    "- how many observations?\n",
    "- how many features (variables)?\n",
    "\n",
    "\n",
    "In the cell below print the number of rows and columns in `movie_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1b**\n",
    "\n",
    "- what does your data look like?\n",
    "- which are the dependent variables?\n",
    "\n",
    "In the cell below output the first 10 rows of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1c**\n",
    "\n",
    "- are any data missing or incorrect?\n",
    "- what are the primary statistics for each feature?\n",
    "\n",
    "Get a basic statisical description of the data. In the first cell describe the numeric data and in the second describe the objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1d**\n",
    "\n",
    "- what are the data types?\n",
    "- are variables numeric or categorical?\n",
    "\n",
    "Get the information about your data frame. You'll want to output the name of each column, the non-null count and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of data\n",
    "\n",
    "How you analyze the data will depend on its type.\n",
    "\n",
    "- **Categorical** - Data that can take on one of a limited, and usually fixed, number of possible values, assigning each row to one of these value often refered to as a category or group. Often type `object` in pandas.\n",
    "    - **Nominal** - Categorical data with no inherent ordering between the categories (e.g. vehicle types)\n",
    "    - **Ordinal** - Categorical data with an inherent ordering, but where the “differences” between categories has no numerical meaning (e.g. agree, strongly agree, etc)\n",
    "- **Numeric/Continuous** - Data that is a number which represents a interval or ratio as described below. Often type `int` or `float` in pandas.\n",
    "    - **Interval** - Numeric data with ordering, where relative differences in interval data have meaning (e.g. temperatures)\n",
    "    - **Ratio** - Numeric data where the ratio between measurements has some meaning\n",
    "\n",
    "One thing to be careful of is if categorical variables are stored as numbers i.e. group_numbers from the set [1, 2, 3, 4]. A good test is to think if you can perform math on the data and have it make sense. i.e. for the groups: 1 - 2 = 1 but this doesn't say anything about the relationship between group 1 and 2. \n",
    "\n",
    "- **Dates** - Dates are a tricky third type of data that can be treated as either categorical or numeric depending on the application. \n",
    "    - **Categorical** - If you break a date into it's parts you can treat it as categorical data. For example which day of the week has the largest number of ticket sales. Day of the week is a category in this application.\n",
    "    - **Numeric/Continuous** - You can treat dates as numbers if you think about them as time since a fixed point. Let's say you treated a water sample on 2025-01-01 and each day you measured how clean the water was. Each row would have a date that you tell you how may days have elapsed since 2025-01-01. You could calculate the number of days and use that as a number in a line graph or you could simply use the date and it would convey the same information. \n",
    "\n",
    "In this data set we have `year` which describes the year the movie was released. We will use this as numeric for our exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Getting list of features\n",
    "Create two lists: numeric_features and categorical_features which have the column name of each. \n",
    "\n",
    "There are a few ways to do this:\n",
    "1. Use `dtypes`, `columns` and list comprehension\n",
    "2. Use `select_dtypes` and `columns`\n",
    "\n",
    "Impliment both ways and then chec that they are the same lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Print out values counts of categorical features\n",
    "It is often easier to loop through the list of your columns and perform some basic exploration of columns of the same types. For this problem you will loop through all categorical_features and if they have 10 or fewer values print out the count of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Histograms for Numeric Columns\n",
    "For all numeric_features:\n",
    "1. Print the name of the column\n",
    "2. Create a histogram plot using df.plot.histogram \n",
    "3. Make the histogram show using plt.show()\n",
    "\n",
    "For 5 points extra credit you can set the bin width using Freedman–Diaconis rule and the number of bins such that \n",
    "number_bins = (max - min)/bin_width\n",
    "\n",
    "https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Numerical Relationships\n",
    "The other thing we often want to understand is if there is a relaionship between numerical features. Scatter plot matricies are a quick way to evaluate if there is a relationship between a collection of numerical features.\n",
    "\n",
    "Looking at the histograms above we have several features that look more categorical than numeric i.e. decade code. Because of this we will only create a scatter plot matrix with only a subset of the features:\n",
    "\n",
    "`['budget', 'domgross', 'intgross', 'budget_2013$', 'domgross_2013$', 'intgross_2013$']`\n",
    "\n",
    "There are a few scatter plot matricies avaible in the Python data ecosystem. You will use two of them in this problem:\n",
    "\n",
    "1. pd.plotting.scatter_matrix\n",
    "2. seaborn.pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Opperations\n",
    "\n",
    "For this section of applying our linear algebra learnings we will work through a few matrix opperation problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Matrix Addition\n",
    "\n",
    "Implement matrix addition element-wise using two for loops over rows and columns. What happens when you try to add two matrices with mismatching sizes? This exercise will help you think about breaking down a matrix into rows, columns, and individual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: Matrix Multiplication\n",
    "\n",
    "Code matrix multiplication using for loops. Confirm your results against using the numpy @ operator. This exercise will help you solidify your understanding of matrix multiplication, but in practice, it’s always better to use @ instead of writing out a double for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: Matrix Opperation Commutivity and Distributivity\n",
    "\n",
    "Matrix addition and scalar multiplication obey the mathematical laws of commutivity and distributivity. That means that the following equations give the same results (assume that the matrices $A$ and $B$ are the same size and that  is some scalar):\n",
    "\n",
    "$$\\sigma (A + B) = \\sigma A + \\sigma B = A \\sigma + B \\sigma$$\n",
    "\n",
    "Rather than proving this mathematically, you are going to demonstrate it through coding. In Python, create two random-numbers matrices of size \n",
    " and a random scalar. Then implement the three expressions in the previous equation. You’ll need to figure out a way to confirm that the three results are equal. Keep in mind that tiny computer precision errors in the range of \n",
    " should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Checking Matrix Symmetry\n",
    "\n",
    "In this exercise, you will write a Python function that checks whether a matrix is symmetric. It should take a matrix as input, and should output a boolean True if the matrix is symmetric or False if the matrix is nonsymmetric. Keep in mind that small computer rounding/precision errors can make “equal” matrices appear unequal. Therefore, you will need to test for equality with some reasonable tolerance. Test the function on symmetric and nonsymmetric matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AD_450_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
